"""
Author: Abubakar Kasule
Description: Script to generate confussion matrices from the time series information stored in ./Data/Wave_normalize_script/
Note: Some of the code was generated by JDIT's GUI
"""

# Imports
import seaborn as sn
import pandas as pd
import matplotlib.pyplot as plt
from jpype import *
import numpy
import sys
import csv


# Our python data file readers are a bit of a hack, python users will do better on this:
sys.path.append("./infodynamics-dist-1.5/demos/python")   # Needs to change

# Add JIDT jar library to the path
jarLocation = "./infodynamics-dist-1.5/infodynamics.jar"  

# Start the JVM (add the "-Xmx" option with say 1024M if you get crashes due to not enough memory space)
startJVM(getDefaultJVMPath(), "-ea", "-Djava.class.path=" + jarLocation)


def generate_binned(data):
    global dataFile

    # Create array to stroe marix information. Each entry represents a Transfeer entropy value between a source and destination column from the original time series datafile
    n = len(data[0])
    array = list()

    for i in range(n):
        temp = list()

        for j in range(n):
            temp.append(0)

        array.append(temp)

    # 1. Construct the calculator:
    calcClass = JPackage("infodynamics.measures.discrete").TransferEntropyCalculatorDiscrete

    # Needs to change
    calc = calcClass(2, 1, 1, 1, 1, 14)   # 14 day delay due to that being the incubation time for covid

    # 2. No other properties to set for discrete calculators.
    mUtils = JPackage('infodynamics.utils').MatrixUtils
    
    # Compute for all pairs:
    for s in range(n):
        for d in range(n):
            # For each source-dest pair:
            if (s == d):
                continue
            source = mUtils.discretise(JArray(JDouble, 1)(data[:,s].tolist()), 2)
            destination = mUtils.discretise(JArray(JDouble, 1)(data[:,d].tolist()), 2)

            # 3. Initialise the calculator for (re-)use:
            calc.initialise()
            # 4. Supply the sample data:
            calc.addObservations(source, destination)
            # 5. Compute the estimate:
            result = calc.computeAverageLocalOfObservations()

            array[s][d] = result

            print("\t\tTE_Binned(col_%d -> col_%d) = %.4f bits" %
                (s, d, result), file =dataFile)

    return array

def generate_gaussian(data):
    global dataFile

    n = len(data[0])
    array = list()

    for i in range(n):
        temp = list()

        for j in range(n):
            temp.append(-1)

        array.append(temp)

    # 1. Construct the calculator:
    calcClass = JPackage("infodynamics.measures.continuous.gaussian").TransferEntropyCalculatorGaussian
    calc = calcClass()
    # 2. Set any properties to non-default values:
    # No properties were set to non-default values

    # Compute for all pairs:
    for s in range(n):
        for d in range(n):
            # For each source-dest pair:
            if (s == d):
                continue
            source = data[:, s]
            destination = data[:, d]

            # 3. Initialise the calculator for (re-)use:
            calc.initialise()
            # 4. Supply the sample data:
            calc.setObservations(source, destination)
            # 5. Compute the estimate:
            result = calc.computeAverageLocalOfObservations()

            array[s][d] = result

            print("\t\tTE_Gaussian(col_%d -> col_%d) = %.4f nats" %
                (s, d, result), file =dataFile)

    return array

dataFile = open('output/WaveData.txt', 'w')

# Generate figueres for all waves
for i in range(1, 7):
    print("\n\n\nWave " + str(i) + " Data:\n\n", file =dataFile)

    # initializing the titles and rows list
    fields = []
    rows = []
    filename = "./Data/Wave_normalize_script/wave" + str(i) + ".csv" # Needs to change
    
    # reading csv file
    with open(filename, 'r') as csvfile:
        # creating a csv reader object
        csvreader = csv.reader(csvfile)
        
        # extracting field names through first row
        labels = next(csvreader)
    
        # extracting each data row one by one
        for row in csvreader:
            rows.append(list([int(i) for i in row]))

    # As numpy array:
    data = numpy.array(rows)

    print("\tBinned Transfer Entropy Data:", file =dataFile)

    array = generate_binned(data)
    df_cm = pd.DataFrame(array, index =labels,
                    columns = labels)
    plt.figure(figsize = (20,20))
    sn.heatmap(df_cm, annot=True)
    plt.savefig("output/wave" + str(i) + "_binned")

    print("\tGaussian Transfer Entropy Data:", file =dataFile)

    array = generate_gaussian(data)
    df_cm = pd.DataFrame(array, index =labels,
                    columns = labels)
    plt.figure(figsize = (20,20))
    plt.xlabel("Destination")
    plt.ylabel("Source")
    sn.heatmap(df_cm, annot=True)
    
    plt.savefig("output/wave" + str(i) + "_gaussian")

dataFile.close()